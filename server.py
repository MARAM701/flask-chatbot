from flask import Flask, request, jsonify, make_response
from flask_cors import CORS
import logging
import os
from docx import Document
import re
import google.generativeai as genai  # Changed from OpenAI to Gemini

# Set up logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('server')

DOCUMENT_PATH = os.getenv('DOCUMENT_PATH', 'test_second.docx')
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")  # New API key for Gemini

app = Flask(__name__)
CORS(app,
     resources={
         r"/api/*": {
             "origins": ["https://superlative-belekoy-1319b4.netlify.app"],
             "methods": ["POST", "OPTIONS"],
             "allow_headers": ["Content-Type"],
             "expose_headers": ["Access-Control-Allow-Origin"],
             "supports_credentials": True
         }
     })



class DocumentProcessor:
    def __init__(self):
        self.sections = {}
        self.document_text = "" 
        self.file_header = "" 

    def load_document(self):
        try:
            current_dir = os.getcwd()
            logger.info(f"Current working directory: {current_dir}")

            doc_path = os.path.join(current_dir, DOCUMENT_PATH)
            if not os.path.exists(doc_path):
                logger.error("Document not found")
                return False
            logger.info(f"Loading document from: {doc_path}")

            doc = Document(doc_path) 
                       # Initialize with first header or default
            current_section = None
            current_content = []
            header_pattern = re.compile(r'^(#{3,})\s*(.+?)\s*\1$')




            # Process document using regex to detect headers
            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                if not text:
                    continue

                match = header_pattern.match(text)
                if match:
                    level = len(match.group(1))
                    header_text = match.group(2).strip()
                    logger.debug(f"Found header: {header_text} with level {level}")
                    if level == 3:
                        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø«Ù„Ø§Ø« (###): Ù‡Ø°Ø§ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù„Ù
                        self.file_header = text
                        continue  # Ù„Ø§ ØªÙØ¶ÙŠÙ Ø¥Ù„Ù‰ Ø£ÙŠ Ù‚Ø³Ù…
                    elif level >= 4:
                        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø£Ø±Ø¨Ø¹ Ø£Ùˆ Ø£ÙƒØ«Ø±: Ù‡Ø°Ø§ Ø¹Ù†ÙˆØ§Ù† Ù‚Ø³Ù…
                        if current_section and current_content:
                            self.sections[current_section] = '\n'.join(current_content)
                        current_section = header_text
                        current_content = []
                        continue
                else:
                    # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø·ØŒ ÙŠÙØ¶Ø§Ù Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø­Ø§Ù„ÙŠ
                    current_content.append(text) 
 
                        # Save last section if exists
            if current_section and current_content:
                self.sections[current_section] = '\n'.join(current_content)
            
            # Build full document text with file header and sections
            parts = []
            if self.file_header:
                parts.append(self.file_header)
            for section, content in self.sections.items():
                parts.append(f"=== {section} ===\n{content}\n=== Ù†Ù‡Ø§ÙŠØ© {section} ===")
            self.document_text = "\n\n".join(parts)


            return True

        except Exception as e:
            logger.error(f"Error loading document: {str(e)}", exc_info=True)
            return False


def ask_gemini(question, context):
    """Send the document and question to Gemini API."""
    genai.configure(api_key=GEMINI_API_KEY)  # Configure the library with your API key
    model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp')

    system_prompt = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©.
    ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø´ÙƒÙ„ ØµØ§Ø±Ù…:

    1. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø£Ø®ÙˆØ°Ø© Ù…Ù† Ù‚Ø³Ù… ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·:
    **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:** 
    [Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø§Ù„Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ] [1]

    **Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:**
    "[Ø£ÙˆÙ„ 50 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³]..."

    ğŸ“– Ø§Ù„Ù…ØµØ¯Ø±:
    [Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù] - [Ø§Ø³Ù… Ø§Ù„Ù‚Ø³Ù…]

    2. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø£Ø®ÙˆØ°Ø© Ù…Ù† Ø¹Ø¯Ø© Ø£Ù‚Ø³Ø§Ù…:
    **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**
    [Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø§Ù„Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø¨Ø¹Ø¯ ÙƒÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø©]

    **Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:**
    [1]: "[Ø£ÙˆÙ„ 30 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³]..."
    [2]: "[Ø£ÙˆÙ„ 30 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³]..."

    ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:
    [1]: [Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù] - [Ø§Ø³Ù… Ø§Ù„Ù‚Ø³Ù…]
    [2]: [Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù] - [Ø§Ø³Ù… Ø§Ù„Ù‚Ø³Ù…]

    3. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ÙÙŠ Ø§Ù„Ù†ØµØŒ Ø§ÙƒØªØ¨:
    **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:** Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ø§Ù„Ù†Øµ ØªØ¬ÙŠØ¨ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„.

    4. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ§Ù„ÙŠØ©:
    - Ø§Ø¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†Øµ
    - Ø§Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ù‚Ø¨Ù„ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
    - Ø£Ø¶Ù Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹ [N] Ø¨Ø¹Ø¯ ÙƒÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ù‚ØªØ¨Ø³Ø©
    - Ø§Ù‚ØªØ¨Ø³ ÙÙ‚Ø· Ø£ÙˆÙ„ 50 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ Ù…ØªØ¨ÙˆØ¹Ø© Ø¨Ø«Ù„Ø§Ø« Ù†Ù‚Ø§Ø· (...)
    - Ø±ØªØ¨ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø­Ø³Ø¨ Ø¸Ù‡ÙˆØ±Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"""

    user_message = f"""Ù‚Ù… Ø¨Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ§Ø±Ø¯Ø©.
    ØªØ£ÙƒØ¯ Ù…Ù† Ø°ÙƒØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©.

Ø§Ù„Ù†Øµ:
{context}

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {question}"""

    try:
        # Combine system_prompt and user_message into a single message
        combined_message = system_prompt + "\n\n" + user_message

        response = model.generate_content(
            combined_message,
            generation_config={
                "temperature": 0.1,
                "max_output_tokens": 1500
            }
        )
        gemini_response = response.text

        return process_gpt_response(gemini_response)

    except Exception as e:
        logger.error(f"Error calling Gemini API: {str(e)}")
        return "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨."

def process_gpt_response(gpt_response):
    """Format GPT response with numbered references using detected file name and section header."""
    # Check if the response indicates no information was found
    if "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª" in gpt_response:
        return gpt_response

    # Extract the sources section from the GPT response
    sources_section = None
    if "ğŸ“– Ø§Ù„Ù…ØµØ¯Ø±:" in gpt_response:
        # Convert single source format to multiple sources format
        gpt_response = gpt_response.replace("ğŸ“– Ø§Ù„Ù…ØµØ¯Ø±:", "ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:\n[1]:")
        sources_section = re.search(r'ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:(.*?)(?=\*\*|\n\n|\Z)', gpt_response, re.DOTALL)
    elif "ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:" in gpt_response:
        sources_section = re.search(r'ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:(.*?)(?=\*\*|\n\n|\Z)', gpt_response, re.DOTALL)

    # Dynamically extract the file name from the global DocumentProcessor instance's file_header
    file_name = "Unknown File"
    try:
        # Assume DOC_PROCESSOR is a global instance of DocumentProcessor
        header_text = DOC_PROCESSOR.file_header  # e.g., "### Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù: Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø³Ù†ÙˆÙŠ Ù¢Ù Ù¢Ù¢ ###"
        match = re.search(r'Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù:\s*(.*?)\s*#', header_text)
        if match:
            file_name = match.group(1).strip()
    except Exception as e:
        file_name = "Unknown File"

    # If sources section is found, process each reference line
    if sources_section:
        sources_text = sources_section.group(1)
        modified_sources = []
        # Iterate over each reference line using regex
        for ref_match in re.finditer(r'\[(\d+)\]:\s*(.*?)(?=\n|$)', sources_text):
            ref_num = ref_match.group(1)
            section_name = ref_match.group(2).strip()
            # Format reference as: [ref_num]: {file_name} - {section_name}
            modified_sources.append(f'[{ref_num}]: {file_name} - {section_name}')
        if modified_sources:
            new_sources = 'ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:\n' + '\n'.join(modified_sources)
            gpt_response = re.sub(
                r'ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:.*?(?=\*\*|\n\n|\Z)',
                new_sources,
                gpt_response,
                flags=re.DOTALL
            )

    return gpt_response





# Create a global instance of DocumentProcessor and load the document
DOC_PROCESSOR = DocumentProcessor()
if not DOC_PROCESSOR.load_document():
    logger.error("Failed to load the document.")


@app.route('/api/ask', methods=['POST', 'OPTIONS'])
def ask_question():
    if request.method == "OPTIONS":
        return _build_cors_preflight_response()

    data = request.json
    question = data.get('question')

    if not question:
        return jsonify({"error": "Ù„Ù… ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ø³Ø¤Ø§Ù„"}), 400

    logger.info(f"Received question: {question}")

    if not DOC_PROCESSOR.sections:
        return jsonify({"error": "Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­."}), 500

    # Format document sections
    context_parts = []
    for section, content in DOC_PROCESSOR.sections.items():
        context_parts.append(f"""
=== {section} ===
{content}
=== Ù†Ù‡Ø§ÙŠØ© {section} ===
""")

    context = "\n\n".join(context_parts)

    answer = ask_gemini(question, context)
    return jsonify({"answer": answer})


@app.route('/api/sections', methods=['GET'])
def list_sections():
    """Debug endpoint to list all document sections"""
    if not DOC_PROCESSOR.sections:
        return jsonify({"error": "Document not loaded"}), 500

    sections = []
    for section, content in DOC_PROCESSOR.sections.items():
        sections.append({
            "title": section,
            "char_count": len(content),
            
        })

    return jsonify({"sections": sections})


def _build_cors_preflight_response():
    response = make_response()
    response.headers.add('Access-Control-Allow-Origin', 'https://superlative-belekoy-1319b4.netlify.app')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type')
    response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')
    return response


@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "healthy",
        "document_loaded": bool(DOC_PROCESSOR.sections),
        "document_path": DOCUMENT_PATH,
        "sections_count": len(DOC_PROCESSOR.sections)
    }), 200


if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
