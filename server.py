from flask import Flask, request, jsonify, make_response
from flask_cors import CORS
import logging
import os
from docx import Document
import re
from openai import OpenAI

# Set up logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('server')

DOCUMENT_PATH = os.getenv('DOCUMENT_PATH', 'arabic_file.docx')
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

app = Flask(__name__)
CORS(app, 
    resources={
        r"/api/*": {
            "origins": ["https://superlative-belekoy-1319b4.netlify.app"],
            "methods": ["POST", "OPTIONS"],
            "allow_headers": ["Content-Type"],
            "expose_headers": ["Access-Control-Allow-Origin"],
            "supports_credentials": True
        }
    })

# Define known headers in order of appearance
KNOWN_HEADERS = [
    "ูููุฉ ูุนุงูู ุฑุฆูุณ ูุฌูุณ ุงูุฅุฏุงุฑุฉ",
    "ูููุฉ ูุนุงูู ุฑุฆูุณ ุงููุฏููุฉ",
    "ูุฌูุณ ุฅุฏุงุฑุฉ ูุฏููุฉ ุงูููู ุนุจุฏุงูุนุฒูุฒ ููุนููู ูุงูุชูููุฉ",
    "ุชุนุฑูู ุงููุตุทูุญุงุช ูุงูุงุฎุชุตุงุฑุงุช",
    "ุงูููุฎุต ุงูุชูููุฐู",
    "ุฅูุฌุงุฒุงุช ุงูุนุงู ูู ุฃุฑูุงู"
]

# Add TOC page mapping
TOC_PAGE_MAP = {
    "ูููุฉ ูุนุงูู ุฑุฆูุณ ูุฌูุณ ุงูุฅุฏุงุฑุฉ": 8,
    "ูููุฉ ูุนุงูู ุฑุฆูุณ ุงููุฏููุฉ": 10,
    "ูุฌูุณ ุฅุฏุงุฑุฉ ูุฏููุฉ ุงูููู ุนุจุฏุงูุนุฒูุฒ ููุนููู ูุงูุชูููุฉ": 12,
    "ุชุนุฑูู ุงููุตุทูุญุงุช ูุงูุงุฎุชุตุงุฑุงุช": 14,
    "ุงูููุฎุต ุงูุชูููุฐู": 18,
    "ุงูุฌุงุฒุงุช ุงูุนุงู ูู ุฃุฑูุงู": 20
}

class DocumentProcessor:
    def __init__(self):
        self.sections = {}
        self.document_text = ""

    def load_document(self):
        try:
            current_dir = os.getcwd()
            logger.info(f"Current working directory: {current_dir}")
            
            files = os.listdir(current_dir)
            docx_file = next((f for f in files if f.strip().endswith('arabic_file.docx')), None)
            
            if not docx_file:
                logger.error("Document not found")
                return False
                
            doc_path = os.path.join(current_dir, docx_file)
            logger.info(f"Loading document from: {doc_path}")
            
            doc = Document(doc_path)
            
            # Initialize with first header or default
            current_section = KNOWN_HEADERS[0] if KNOWN_HEADERS else "ููุฏูุฉ"
            current_content = []
            
            # Process document
            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                if not text:
                    continue
                
                # Check if this paragraph matches any known header
                if text in KNOWN_HEADERS:
                    # Save previous section content if exists
                    if current_content:
                        self.sections[current_section] = '\n'.join(current_content)
                    # Start new section
                    current_section = text
                    current_content = []
                    logger.debug(f"Found header: {text}")
                else:
                    # This is normal text ("ุนุงุฏู"), add to current section
                    current_content.append(text)
            
            # Save last section
            if current_content:
                self.sections[current_section] = '\n'.join(current_content)
            
            # Store full document text
            self.document_text = '\n\n'.join(para.text for para in doc.paragraphs if para.text.strip())
            
            return True
            
        except Exception as e:
            logger.error(f"Error loading document: {str(e)}", exc_info=True)
            return False

def process_gpt_response(gpt_response):
    """Format GPT response maintaining emoji source reference and adding numbered references"""
    # First find all section references
    section_matches = re.finditer(r"ุงููุตุฏุฑ: ([^-\n]+)", gpt_response)
    
    # Collect all unique sections while preserving the response format
    sections = []
    seen_sections = set()
    
    result = gpt_response
    
    # Process each section reference
    for match in section_matches:
        section_name = match.group(1).strip()
        if section_name not in seen_sections:
            sections.append(section_name)
            seen_sections.add(section_name)
            
            # Get page number for this section
            page_number = TOC_PAGE_MAP.get(section_name, "ุบูุฑ ูุชููุฑ")
            
            # Replace the source reference with emoji format, handling potential duplicate emojis
            result = re.sub(
                f'๐* *ุงููุตุฏุฑ: {re.escape(section_name)}',
                f'๐ ุงููุตุฏุฑ: {section_name} - ุตูุญุฉ {page_number}',
                result
            )
            # Clean up any remaining duplicate emojis
            result = re.sub(r'๐\s*๐\s*', '๐ ', result)
    
    # Add numbered references at the end if there are sections
    if sections:
        result += "\n\nุงููุฑุงุฌุน:\n"
        for idx, section in enumerate(sections, 1):
            page_number = TOC_PAGE_MAP.get(section, "ุบูุฑ ูุชููุฑ")
            result += f"[{idx}] {section} - ุตูุญุฉ {page_number}\n"
    
    return result

def ask_gpt4(question, context):
    """Send the document and question to OpenAI GPT-4 API."""
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    system_prompt = """ุฃูุช ูุณุงุนุฏ ูุชุฎุตุต ูู ุชุญููู ุงููุตูุต ุงูุนุฑุจูุฉ ูุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุจุฏูุฉ ุนุงููุฉ.
    ูุฌุจ ุนููู ุงูุงูุชุฒุงู ุจุงูููุงุนุฏ ุงูุชุงููุฉ ุจุดูู ุตุงุฑู:

    1. ูุฏู ุงูุฅุฌุงุจุฉ ุจุงูุชุฑุชูุจ ุงูุชุงูู:
    ุฃููุงู: ุงูุฅุฌุงุจุฉ ุงููุงููุฉ
    **ุงูุฅุฌุงุจุฉ:** [ุงูุชุจ ุฅุฌุงุจุฉ ูุงููุฉ ูููุธูุฉ ุชุฌูุน ุงููุนูููุงุช ูู ูู ุงููุตุงุฏุฑ]

    ุซุงููุงู: ุงููุตูุต ุงููุตุฏุฑูุฉ ููู ูุณู:
    ๐ ุงููุตุฏุฑ: [ุงุณู ุงููุณู ุงูุฃูู] - ุตูุญุฉ [ุฑูู]
    **ุงููุต ุงูุฃุตูู:** "[ุงููุต ุงูุญุฑูู ูู ุงููุณู ุงูุฃูู]"

    ๐ ุงููุตุฏุฑ: [ุงุณู ุงููุณู ุงูุซุงูู] - ุตูุญุฉ [ุฑูู]
    **ุงููุต ุงูุฃุตูู:** "[ุงููุต ุงูุญุฑูู ูู ุงููุณู ุงูุซุงูู]"
    (ูููุฐุง ููู ูุณู)

    ุซุงูุซุงู: ูุงุฆูุฉ ุงููุฑุงุฌุน ูู ุงูููุงูุฉ

    2. ุนูุฏ ุงูุฅุฌุงุจุฉ ุนูู ุฃุณุฆูุฉ ุงูุฅูุฌุงุฒุงุช ุฃู ุงููุชุงุฆุฌ:
    - ูุธู ุงูุฅุฌุงุจุฉ ูู ููุงุท ูุฑููุฉ ุฃู ูุฑุชุจุฉ
    - ุงุฌูุน ุงููุนูููุงุช ุงููุชุดุงุจูุฉ ุชุญุช ุนูุงููู ููุญุฏุฉ
    - ุฑุชุจ ุงูููุงุท ุญุณุจ ุงูุฃูููุฉ ุฃู ุงูุชุณูุณู ุงูููุทูู

    3. ุงูุชุฒู ุจุงูููุงุนุฏ ุงูุชุงููุฉ:
    - ุงุนุชูุฏ ููุท ุนูู ุงููุนูููุงุช ุงูููุฌูุฏุฉ ูู ุงููุต
    - ูุง ุชุณุชูุชุฌ ุฃู ุชุฎูู
    - ุงููู ุงููุต ุงูุฃุตูู ุญุฑููุงู ููู ูุณู
    - ุญุงูุธ ุนูู ุชุฑุชูุจ: ุงูุฅุฌุงุจุฉุ ุซู ุงููุตูุต ุงููุตุฏุฑูุฉุ ุซู ุงููุฑุงุฌุน"""

    1. ูุฏู ุงูุฅุฌุงุจุฉ ุจุงูุชูุณูู ุงูุชุงูู ุจุงูุถุจุท:
    **ุงูุฅุฌุงุจุฉ:** [ุฅุฌุงุจุชู ุงููุจููุฉ ุนูู ุงููุต]
    
    ุฅุฐุง ูุงูุช ุงููุนูููุงุช ูู ูุณู ูุงุญุฏ:
    ๐ ุงููุตุฏุฑ: [ุงุณู ุงููุณู]
    **ุงููุต ุงูุฃุตูู:** "[ุงููุต ุงูุญุฑูู ูู ุงููุณุชูุฏ]"
    
    ุฅุฐุง ูุงูุช ุงููุนูููุงุช ูู ุนุฏุฉ ุฃูุณุงู:
    ๐ ุงููุตุฏุฑ: [ุงุณู ุงููุณู ุงูุฃูู]
    **ุงููุต ุงูุฃูู:** "[ุงููุต ุงูุญุฑูู ุงูุฃูู]"
    ๐ ุงููุตุฏุฑ: [ุงุณู ุงููุณู ุงูุซุงูู]
    **ุงููุต ุงูุซุงูู:** "[ุงููุต ุงูุญุฑูู ุงูุซุงูู]"
    (ูููุฐุง ููู ูุณู)

    2. ุฅุฐุง ูู ุชุฌุฏ ุงููุนูููุฉ ูู ุงููุตุ ุงูุชุจ:
    **ุงูุฅุฌุงุจุฉ:** ุนุฐุฑุงูุ ูู ุฃุฌุฏ ูุนูููุงุช ูู ุงููุต ุชุฌูุจ ุนูู ูุฐุง ุงูุณุคุงู.

    3. ุงูุชุฒู ุจุงูููุงุนุฏ ุงูุชุงููุฉ:
    - ุงุนุชูุฏ ููุท ุนูู ุงููุนูููุงุช ุงูููุฌูุฏุฉ ูู ุงููุต
    - ูุง ุชุณุชูุชุฌ ุฃู ุชุฎูู
    - ุงููู ุงููุต ุงูุฃุตูู ุญุฑููุงู ููู ูุณู
    - ุงุฐูุฑ ุงููุตุฏุฑ ููู ูุณู ุจุงูุชูุณูู ุงููุทููุจ
    - ุชุนุงูู ูุน ุงูููุงุฆู ูุงูููุงุท ูุฌุฒุก ูู ุงููุนูููุงุช"""

    user_message = f"""ููุง ูุต ุงูุชูุฑูุฑ. ุฃุฌุจ ุนูู ุณุคุงู ุงููุณุชุฎุฏู ุจูุงุกู ุนูู ุงููุนูููุงุช ุงููุงุฑุฏุฉ ูู ุงููุต ููุท.

ุงููุต:
{context}

ุณุคุงู ุงููุณุชุฎุฏู: {question}"""

    try:
        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1,
            max_tokens=1024
        )
        
        gpt_response = response.choices[0].message.content
        return process_gpt_response(gpt_response)
            
    except Exception as e:
        logger.error(f"Error calling OpenAI API: {str(e)}")
        return "ุญุฏุซ ุฎุทุฃ ูู ูุนุงูุฌุฉ ุงูุทูุจ."

# Initialize document processor
DOC_PROCESSOR = DocumentProcessor()
DOC_PROCESSOR.load_document()

@app.route('/api/ask', methods=['POST', 'OPTIONS'])
def ask_question():
    if request.method == "OPTIONS":
        return _build_cors_preflight_response()
    
    data = request.json
    question = data.get('question')
    
    if not question:
        return jsonify({"error": "ูู ูุชู ุชูุฏูู ุณุคุงู"}), 400

    logger.info(f"Received question: {question}")
    
    if not DOC_PROCESSOR.sections:
        return jsonify({"error": "ูู ูุชู ุชุญููู ุงููุซููุฉ ุจุดูู ุตุญูุญ."}), 500

    # Format document sections
    context_parts = []
    for section, content in DOC_PROCESSOR.sections.items():
        context_parts.append(f"""
=== {section} ===
{content}
=== ููุงูุฉ {section} ===
""")
    
    context = "\n\n".join(context_parts)
    
    answer = ask_gpt4(question, context)
    return jsonify({"answer": answer})

@app.route('/api/sections', methods=['GET'])
def list_sections():
    """Debug endpoint to list all document sections"""
    if not DOC_PROCESSOR.sections:
        return jsonify({"error": "Document not loaded"}), 500
        
    sections = []
    for section, content in DOC_PROCESSOR.sections.items():
        sections.append({
            "title": section,
            "char_count": len(content),
            "page": TOC_PAGE_MAP.get(section, "ุบูุฑ ูุชููุฑ")
        })
    
    return jsonify({"sections": sections})

def _build_cors_preflight_response():
    response = make_response()
    response.headers.add('Access-Control-Allow-Origin', 'https://superlative-belekoy-1319b4.netlify.app')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type')
    response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')
    return response

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "healthy",
        "document_loaded": bool(DOC_PROCESSOR.sections),
        "document_path": DOCUMENT_PATH,
        "sections_count": len(DOC_PROCESSOR.sections)
    }), 200

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
