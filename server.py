from flask import Flask, request, jsonify, make_response
from flask_cors import CORS
import logging
import os
import re
import json
from openai import OpenAI

# Set up logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('server')

# Update to handle multiple JSON files
JSON_FILE_PATH_2016 = os.getenv('JSON_FILE_PATH_2016', 'report_2016.json')
JSON_FILE_PATH_2017 = os.getenv('JSON_FILE_PATH_2017', 'report_2017.json')
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

app = Flask(__name__)
CORS(app, 
    resources={
        r"/api/*": {
            "origins": ["https://superlative-belekoy-1319b4.netlify.app"],
            "methods": ["POST", "OPTIONS"],
            "allow_headers": ["Content-Type"],
            "expose_headers": ["Access-Control-Allow-Origin"],
            "supports_credentials": True
        }
    })

# Load JSON data at server startup
REPORT_DATA = []

def load_json_data():
    """Load and preprocess both JSON files at server startup"""
    global REPORT_DATA
    try:
        current_dir = os.getcwd()
        logger.info(f"Current working directory: {current_dir}")
        
        # Load 2016 report
        json_path_2016 = os.path.join(current_dir, JSON_FILE_PATH_2016)
        logger.info(f"Loading 2016 JSON file from: {json_path_2016}")
        
        with open(json_path_2016, 'r', encoding='utf-8') as file:
            report_data_2016 = json.load(file)
        
        logger.info(f"Successfully loaded {len(report_data_2016)} sections from 2016 report")
        
        # Load 2017 report
        json_path_2017 = os.path.join(current_dir, JSON_FILE_PATH_2017)
        logger.info(f"Loading 2017 JSON file from: {json_path_2017}")
        
        try:
            with open(json_path_2017, 'r', encoding='utf-8') as file:
                report_data_2017 = json.load(file)
            
            logger.info(f"Successfully loaded {len(report_data_2017)} sections from 2017 report")
            
            # Combine both reports into one list
            REPORT_DATA = report_data_2016 + report_data_2017
            
            logger.info(f"Combined {len(REPORT_DATA)} total sections from both reports")
        except FileNotFoundError:
            # Handle case where 2017 report doesn't exist yet
            logger.warning(f"2017 report file not found. Using only 2016 report.")
            REPORT_DATA = report_data_2016
            
        return True
    except Exception as e:
        logger.error(f"Error loading JSON files: {str(e)}", exc_info=True)
        return False

def ask_gpt4(question, context):
    """Send the document and question to OpenAI GPT-4 API."""
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    # No need to extract a single file name since we now have multiple files
    # Each section has its own file_name field
    
    system_prompt = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©.

Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ±Ø³Ù„ ÙÙ‚Ø· ØªØ­ÙŠØ© Ø£Ùˆ Ø³Ù„Ø§Ù… (Ù…Ø«Ù„ "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…" Ø£Ùˆ "Ù…Ø±Ø­Ø¨Ø§" Ø£Ùˆ "ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±")ØŒ Ø±Ø¯ Ø¨ØªØ­ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© ÙˆÙ…Ø­ØªØ±Ù…Ø© Ù…ØªØ¨ÙˆØ¹Ø© Ø¨Ø¹Ø¨Ø§Ø±Ø© Ù…Ø«Ù„:
"ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„ØªÙƒ Ø­ÙˆÙ„ ØªÙ‚Ø§Ø±ÙŠØ± ÙƒØ§ÙƒØ³Øª Ø§Ù„Ø³Ù†ÙˆÙŠÙ‡."

ÙˆÙ„ÙƒÙ†ØŒ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ù…Ø­Ø¯Ø¯Ø§Ù‹ØŒ Ø¹Ù„ÙŠÙƒ Ø£Ù† ØªØ¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…ØªØ§Ø­Ø© ÙˆØªØ¬ÙŠØ¨ ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ§Ù„ÙŠØ©:

1. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø£Ø®ÙˆØ°Ø© Ù…Ù† Ù‚Ø³Ù… ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·:
**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:** 
[Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø§Ù„Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ] [1]

**Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:**
"[Ø£ÙˆÙ„ 50 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³]..."
    
ğŸ“– Ø§Ù„Ù…ØµØ¯Ø±:
[Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù] - [Ø§Ø³Ù… Ø§Ù„Ù‚Ø³Ù…]

2. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø£Ø®ÙˆØ°Ø© Ù…Ù† Ø¹Ø¯Ø© Ø£Ù‚Ø³Ø§Ù…:
**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**
[Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø§Ù„Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø¨Ø¹Ø¯ ÙƒÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø©]

**Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:**
[1]: "[Ø£ÙˆÙ„ 30 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³]..."
[2]: "[Ø£ÙˆÙ„ 30 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³]..."
    
ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:
[1]: [Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù„Ù„Ù‚Ø³Ù… Ø§Ù„Ø£ÙˆÙ„] - [Ø§Ø³Ù… Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø£ÙˆÙ„]
[2]: [Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù„Ù„Ù‚Ø³Ù… Ø§Ù„Ø«Ø§Ù†ÙŠ] - [Ø§Ø³Ù… Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø«Ø§Ù†ÙŠ]

3. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ÙÙŠ Ø§Ù„Ù†ØµØŒ Ø§ÙƒØªØ¨:
**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:** Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ø§Ù„Ù†Øµ ØªØ¬ÙŠØ¨ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„.

4. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ§Ù„ÙŠØ©:
- Ø§Ø¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†Øµ
- Ø§Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ù‚Ø¨Ù„ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
- Ø£Ø¶Ù Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹ [N] Ø¨Ø¹Ø¯ ÙƒÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ù‚ØªØ¨Ø³Ø©
- Ø§Ù‚ØªØ¨Ø³ ÙÙ‚Ø· Ø£ÙˆÙ„ 50 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ Ù…ØªØ¨ÙˆØ¹Ø© Ø¨Ø«Ù„Ø§Ø« Ù†Ù‚Ø§Ø· (...)
- Ø±ØªØ¨ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø­Ø³Ø¨ Ø¸Ù‡ÙˆØ±Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"""

    user_message = f"""Ù‚Ù… Ø¨Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ§Ø±Ø¯Ø©.
    ØªØ£ÙƒØ¯ Ù…Ù† Ø°ÙƒØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©.

Ø§Ù„Ù†Øµ:
{context}

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {question}"""

    try:
        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1,
            max_tokens=1500
        )
        
        gpt_response = response.choices[0].message.content
        return process_gpt_response(gpt_response)
            
    except Exception as e:
        logger.error(f"Error calling OpenAI API: {str(e)}")
        return "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨."

def process_gpt_response(gpt_response):
    """Format GPT response using the exact file_name and section_header from JSON data"""
    # Check if it's a "no information found" response
    if "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª" in gpt_response:
        return gpt_response
    
    # Check if it's a greeting response (containing common greeting responses or mentions of KACST)
    greeting_indicators = [
        "ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù…", "Ø£Ù‡Ù„Ø§Ù‹", "Ù…Ø±Ø­Ø¨Ø§Ù‹", "ØµØ¨Ø§Ø­ Ø§Ù„Ù†ÙˆØ±", 
        "ØªÙ‚Ø§Ø±ÙŠØ± ÙƒØ§ÙƒØ³Øª", "ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ", "ÙƒØ§ÙƒØ³Øª"
    ]
    
    if any(indicator in gpt_response for indicator in greeting_indicators):
        return gpt_response
    
    # Handle both single and multiple sources
    if "ğŸ“– Ø§Ù„Ù…ØµØ¯Ø±:" in gpt_response:
        # Convert single source format to multiple source format
        gpt_response = gpt_response.replace("ğŸ“– Ø§Ù„Ù…ØµØ¯Ø±:", "ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:\n[1]:")
    
    # Find all section references in the format after "ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:"
    if "ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:" in gpt_response:
        parts = gpt_response.split("ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:")
        pre_sources = parts[0]
        sources_section = parts[1]
        
        # Process each line in the sources section
        processed_lines = []
        for line in sources_section.strip().split('\n'):
            # Match reference pattern [N]: any text
            match = re.match(r'\[(\d+)\]:\s*(.*?)$', line.strip())
            if match:
                ref_num = match.group(1)
                section_text = match.group(2).strip()
                
                # Extract section name (the last part after any dashes)
                if " - " in section_text:
                    parts = section_text.split(" - ")
                    section_name = parts[-1].strip()
                else:
                    section_name = section_text.strip()
                
                # Try to find the section in REPORT_DATA to get the correct file name
                found = False
                for section in REPORT_DATA:
                    if section.get('section_header') == section_name:
                        file_name = section.get('file_name')
                        processed_lines.append(f'[{ref_num}]: {file_name} - {section_name}')
                        found = True
                        break
                
                if not found:
                    # If section not found in REPORT_DATA, use default format
                    processed_lines.append(f'[{ref_num}]: Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø³Ù†ÙˆÙŠ - {section_name}')
            else:
                # Keep non-reference lines but only if they're not empty
                if line.strip():
                    processed_lines.append(line)
        
        # Reconstruct the response with updated sources
        gpt_response = pre_sources + "ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:\n" + "\n".join(processed_lines)
    
    return gpt_response

@app.route('/api/ask', methods=['POST', 'OPTIONS'])
def ask_question():
    if request.method == "OPTIONS":
        return _build_cors_preflight_response()
    
    data = request.json
    question = data.get('question')
    
    if not question:
        return jsonify({"error": "Ù„Ù… ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ø³Ø¤Ø§Ù„"}), 400

    logger.info(f"Received question: {question}")
    
    if not REPORT_DATA:
        return jsonify({"error": "Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­."}), 500

    # Format JSON data as context
    context_parts = []
    for section in REPORT_DATA:
        file_name = section.get('file_name', '')
        section_header = section.get('section_header', '')
        content = section.get('content', '')
        
        context_parts.append(f"""
=== {section_header} ===
{content}
=== Ù†Ù‡Ø§ÙŠØ© {section_header} ===
""")
    
    context = "\n\n".join(context_parts)
    
    answer = ask_gpt4(question, context)
    return jsonify({"answer": answer})

@app.route('/api/sections', methods=['GET'])
def list_sections():
    """Endpoint to list all document sections"""
    if not REPORT_DATA:
        return jsonify({"error": "JSON data not loaded"}), 500
        
    sections = []
    for section in REPORT_DATA:
        sections.append({
            "file_name": section.get('file_name', ''),
            "title": section.get('section_header', ''),
            "char_count": len(section.get('content', '')),
        })
    
    return jsonify({"sections": sections})

def _build_cors_preflight_response():
    response = make_response()
    response.headers.add('Access-Control-Allow-Origin', 'https://superlative-belekoy-1319b4.netlify.app')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type')
    response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')
    return response

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "healthy",
        "document_loaded": bool(REPORT_DATA),
        "json_files": [JSON_FILE_PATH_2016, JSON_FILE_PATH_2017],
        "sections_count": len(REPORT_DATA)
    }), 200

# Load the JSON data when the server starts
load_json_data()

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
