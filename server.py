from flask import Flask, request, jsonify, make_response
from flask_cors import CORS
import logging
import os
from docx import Document
import re
from openai import OpenAI

# Set up logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('server')

DOCUMENT_PATH = os.getenv('DOCUMENT_PATH', 'arabic_file.docx')
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

app = Flask(__name__)
CORS(app, 
    resources={
        r"/api/*": {
            "origins": ["https://superlative-belekoy-1319b4.netlify.app"],
            "methods": ["POST", "OPTIONS"],
            "allow_headers": ["Content-Type"],
            "expose_headers": ["Access-Control-Allow-Origin"],
            "supports_credentials": True
        }
    })

# Define known headers in order of appearance
KNOWN_HEADERS = [
    "ูููุฉ ูุนุงูู ุฑุฆูุณ ูุฌูุณ ุงูุฅุฏุงุฑุฉ",
    "ูููุฉ ูุนุงูู ุฑุฆูุณ ุงููุฏููุฉ",
    "ูุฌูุณ ุฅุฏุงุฑุฉ ูุฏููุฉ ุงูููู ุนุจุฏุงูุนุฒูุฒ ููุนููู ูุงูุชูููุฉ",
    "ุชุนุฑูู ุงููุตุทูุญุงุช ูุงูุงุฎุชุตุงุฑุงุช",
    "ุงูููุฎุต ุงูุชูููุฐู",
    "ุงูุฌุงุฒุงุช ุงูุนุงู ูู ุงุฑูุงู",
    "ุซุงููุงูู: ุงูุชูุฑูุฑ ุงูุชูุตููู",
    "ููุฌุฒ ุงูุฃุฏุงุก",
    "ุงููุจุงุฏุฑุงุช",
    "ุฃุจุฑุฒ ุงูุฃุนูุงู ูุงูุฅูุฌุงุฒุงุช - ุงูุจุญุซ ูุงูุชุทููุฑ",
    "ูุทุงุน ุงูุตุญุฉ",
    "ูุทุงุน ุงูุงุณุชุฏุงูุฉ ูุงูุจูุฆุฉ",
    "ูุทุงุน ุงูุทุงูุฉ ูุงูุตูุงุนุฉ",
    "ูุทุงุน ุงูุชุตุงุฏูุงุช ุงููุณุชูุจู",
    "ูุงุญู ุงูุงุจุชูุงุฑ",
    "ุงููุฑุงุฌ",
    "ุชุณููู ูููู ุงูุชูููุฉ",
    "ุชุทููุฑ ุงููุฏุฑุงุช ุงูุจุดุฑูู",
    "ุงูุงุฏูููู 32",
    "ูุฑูุฒ ุงูุซูุฑุฉ ุงูุตูุงุนูุฉ ุงูุฑุงุจุนุฉ ุงูุณุนูุฏู",
    "ุฎุฏูุงุช ุงูุงูุชุฑูุช",
    "ุงูุชุญูู ุงูุฑููู",
    "ุงูุชูููุฉ ุงููุณุชุฏุงูุฉ",
    "ุงูุชุนุงูู ูุงูุดุฑุงูุงุช",
    "ุงูุงุชูุงููุงุช ุงูุฏูููุฉ",
    "ุงูุงุชูุงููุงุช ุงููุญููุฉ",
    "ุงูุชูุงุตู ุงูุงุณุชุฑุงุชูุฌู",
    "ุงูุฃูุดุทุฉ ุงูุนูููุฉ",
    "ุงูุฃูุดุทุฉ ุงูุฅุนูุงููุฉ",
    "ุงููุดุงุฑูุงุช ุงูุฏูููุฉ",
    "ุงููุฑุต ูุงูุนูุงูู ุงููุณุงุนุฏู ุนูู ุชุญููููุง",
    "ุงูุชุญุฏูุงุช ูุงูุฏุนู ุงููุทููุจ",
    "ุงููุถุน ุงูุฑุงูู ููููู ุงูุจุดุฑูุฉ",
    "ุงูููุฒุงููุฉ ูุงูุฅูุฑุงุฏุงุช ูุนููุฏ ุงููุดุฑูุนุงุช",
    "ุงูุดุคูู ุงููุงููููุฉ",
    "ุงูุฎุงุชูุฉ"
]

# Add TOC page mapping
TOC_PAGE_MAP = {
    "ูููุฉ ูุนุงูู ุฑุฆูุณ ูุฌูุณ ุงูุฅุฏุงุฑุฉ": 8,
    "ูููุฉ ูุนุงูู ุฑุฆูุณ ุงููุฏููุฉ": 10,
    "ูุฌูุณ ุฅุฏุงุฑุฉ ูุฏููุฉ ุงูููู ุนุจุฏุงูุนุฒูุฒ ููุนููู ูุงูุชูููุฉ": 12,
    "ุชุนุฑูู ุงููุตุทูุญุงุช ูุงูุงุฎุชุตุงุฑุงุช": 14,
    "ุงูููุฎุต ุงูุชูููุฐู": 18,
    "ุงูุฌุงุฒุงุช ุงูุนุงู ูู ุงุฑูุงู": 20,
    "ุซุงููุงูู: ุงูุชูุฑูุฑ ุงูุชูุตููู": 22,
    "ููุฌุฒ ุงูุฃุฏุงุก": 24,
    "ุงููุจุงุฏุฑุงุช": 26,
    "ุฃุจุฑุฒ ุงูุฃุนูุงู ูุงูุฅูุฌุงุฒุงุช - ุงูุจุญุซ ูุงูุชุทููุฑ": 38,
    "ูุทุงุน ุงูุตุญุฉ": 40,
    "ูุทุงุน ุงูุงุณุชุฏุงูุฉ ูุงูุจูุฆุฉ": 54,
    "ูุทุงุน ุงูุทุงูุฉ ูุงูุตูุงุนุฉ": 62,
    "ูุทุงุน ุงูุชุตุงุฏูุงุช ุงููุณุชูุจู": 90,
    "ูุงุญู ุงูุงุจุชูุงุฑ": 120,
    "ุงููุฑุงุฌ": 130,
    "ุชุณููู ูููู ุงูุชูููุฉ": 142,
    "ุชุทููุฑ ุงููุฏุฑุงุช ุงูุจุดุฑูู": 144,
    "ุงูุงุฏูููู 32": 146,
    "ูุฑูุฒ ุงูุซูุฑุฉ ุงูุตูุงุนูุฉ ุงูุฑุงุจุนุฉ ุงูุณุนูุฏู": 152,
    "ุฎุฏูุงุช ุงูุงูุชุฑูุช": 160,
    "ุงูุชุญูู ุงูุฑููู": 164,
    "ุงูุชูููุฉ ุงููุณุชุฏุงูุฉ": 168,
    "ุงูุชุนุงูู ูุงูุดุฑุงูุงุช": 174,
    "ุงูุงุชูุงููุงุช ุงูุฏูููุฉ": 177,
    "ุงูุงุชูุงููุงุช ุงููุญููุฉ": 180,
    "ุงูุชูุงุตู ุงูุงุณุชุฑุงุชูุฌู": 186,
    "ุงูุฃูุดุทุฉ ุงูุนูููุฉ": 188,
    "ุงูุฃูุดุทุฉ ุงูุฅุนูุงููุฉ": 189,
    "ุงููุดุงุฑูุงุช ุงูุฏูููุฉ": 197,
    "ุงููุฑุต ูุงูุนูุงูู ุงููุณุงุนุฏู ุนูู ุชุญููููุง": 208,
    "ุงูุชุญุฏูุงุช ูุงูุฏุนู ุงููุทููุจ": 212,
    "ุงููุถุน ุงูุฑุงูู ููููู ุงูุจุดุฑูุฉ": 216,
    "ุงูููุฒุงููุฉ ูุงูุฅูุฑุงุฏุงุช ูุนููุฏ ุงููุดุฑูุนุงุช": 222,
    "ุงูุดุคูู ุงููุงููููุฉ": 230,
    "ุงูุฎุงุชูุฉ": 232
}

class DocumentProcessor:
    def __init__(self):
        self.sections = {}
        self.document_text = ""

    def load_document(self):
        try:
            current_dir = os.getcwd()
            logger.info(f"Current working directory: {current_dir}")
            
            files = os.listdir(current_dir)
            docx_file = next((f for f in files if f.strip().endswith('arabic_file.docx')), None)
            
            if not docx_file:
                logger.error("Document not found")
                return False
                
            doc_path = os.path.join(current_dir, docx_file)
            logger.info(f"Loading document from: {doc_path}")
            
            doc = Document(doc_path)
            
            # Initialize with first header or default
            current_section = KNOWN_HEADERS[0] if KNOWN_HEADERS else "ููุฏูุฉ"
            current_content = []
            
            # Process document
            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                if not text:
                    continue
                
                # Check if this paragraph matches any known header
                if text in KNOWN_HEADERS:
                    # Save previous section content if exists
                    if current_content:
                        self.sections[current_section] = '\n'.join(current_content)
                    # Start new section
                    current_section = text
                    current_content = []
                    logger.debug(f"Found header: {text}")
                else:
                    # This is normal text ("ุนุงุฏู"), add to current section
                    current_content.append(text)
            
            # Save last section
            if current_content:
                self.sections[current_section] = '\n'.join(current_content)
            
            # Store full document text
            self.document_text = '\n\n'.join(para.text for para in doc.paragraphs if para.text.strip())
            
            return True
            
        except Exception as e:
            logger.error(f"Error loading document: {str(e)}", exc_info=True)
            return False

def ask_gpt4(question, context):
    """Send the document and question to OpenAI GPT-4 API."""
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    system_prompt = """ุฃูุช ูุณุงุนุฏ ูุชุฎุตุต ูู ุชุญููู ุงููุตูุต ุงูุนุฑุจูุฉ ูุงูุฅุฌุงุจุฉ ุนูู ุงูุฃุณุฆูุฉ ุจุฏูุฉ ุนุงููุฉ.
    ูุฌุจ ุนููู ุงูุจุญุซ ูู ุฌููุน ุงูุฃูุณุงู ุงููุชููุฑุฉ ูุงูุงูุชุฒุงู ุจุงูููุงุนุฏ ุงูุชุงููุฉ ุจุดูู ุตุงุฑู:

    1. ุฅุฐุง ูุงูุช ุงููุนูููุงุช ูุฃุฎูุฐุฉ ูู ูุณู ูุงุญุฏ ููุท:
    **ุงูุฅุฌุงุจุฉ:** 
    [ุฅุฌุงุจุชู ุงููุจููุฉ ุนูู ุงููุต] [1]

    **ุงููุต ุงูุฃุตูู:**
    "[ุฃูู 50 ุญุฑู ูู ุงููุต ุงูููุชุจุณ]..."
    
    ๐ ุงููุตุฏุฑ:
    [ุงุณู ุงููุณู] - ุตูุญุฉ [ุฑูู ุงูุตูุญุฉ]

    2. ุฅุฐุง ูุงูุช ุงููุนูููุงุช ูุฃุฎูุฐุฉ ูู ุนุฏุฉ ุฃูุณุงู:
    **ุงูุฅุฌุงุจุฉ:**
    [ุฅุฌุงุจุชู ุงููุจููุฉ ุนูู ุงููุต ูุน ุฑูู ุงููุฑุฌุน ุจุนุฏ ูู ูุนูููุฉ]

    **ุงููุต ุงูุฃุตูู:**
    [1]: "[ุฃูู 30 ุญุฑู ูู ุงููุต ุงูููุชุจุณ]..."
    [2]: "[ุฃูู 30 ุญุฑู ูู ุงููุต ุงูููุชุจุณ]..."
    
    ๐ ุงููุตุงุฏุฑ:
    [1]: [ุงุณู ุงููุณู ุงูุฃูู] - ุตูุญุฉ [ุฑูู ุงูุตูุญุฉ]
    [2]: [ุงุณู ุงููุณู ุงูุซุงูู] - ุตูุญุฉ [ุฑูู ุงูุตูุญุฉ]

    3. ุฅุฐุง ูู ุชุฌุฏ ุงููุนูููุฉ ูู ุงููุตุ ุงูุชุจ:
    **ุงูุฅุฌุงุจุฉ:** ุนุฐุฑุงูุ ูู ุฃุฌุฏ ูุนูููุงุช ูู ุงููุต ุชุฌูุจ ุนูู ูุฐุง ุงูุณุคุงู.

    4. ุงูุชุฒู ุจุงูููุงุนุฏ ุงูุชุงููุฉ:
    - ุงุนุชูุฏ ููุท ุนูู ุงููุนูููุงุช ุงูููุฌูุฏุฉ ูู ุงููุต
    - ุงุจุญุซ ูู ุฌููุน ุงูุฃูุณุงู ูุจู ุชูุฏูู ุงูุฅุฌุงุจุฉ
    - ุฃุถู ุฑูู ุงููุฑุฌุน [N] ุจุนุฏ ูู ูุนูููุฉ ููุชุจุณุฉ
    - ุงูุชุจุณ ููุท ุฃูู 50 ุญุฑู ูู ุงููุต ุงูุฃุตูู ูุชุจูุนุฉ ุจุซูุงุซ ููุงุท (...)
    - ุฑุชุจ ุงููุฑุงุฌุน ุญุณุจ ุธููุฑูุง ูู ุงูุฅุฌุงุจุฉ"""

    user_message = f"""ูู ุจุงูุจุญุซ ูู ุฌููุน ุฃูุณุงู ุงููุต ุงูุชุงูู ูุฃุฌุจ ุนูู ุณุคุงู ุงููุณุชุฎุฏู ุจูุงุกู ุนูู ุงููุนูููุงุช ุงููุงุฑุฏุฉ.
    ุชุฃูุฏ ูู ุฐูุฑ ุฌููุน ุงููุตุงุฏุฑ ุฐุงุช ุงูุตูุฉ.

ุงููุต:
{context}

ุณุคุงู ุงููุณุชุฎุฏู: {question}"""

    try:
        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1,
            max_tokens=1500
        )
        
        gpt_response = response.choices[0].message.content
        return process_gpt_response(gpt_response)
            
    except Exception as e:
        logger.error(f"Error calling OpenAI API: {str(e)}")
        return "ุญุฏุซ ุฎุทุฃ ูู ูุนุงูุฌุฉ ุงูุทูุจ."

def process_gpt_response(gpt_response):
    """Format GPT response with numbered references"""
    # Check if it's a "no information found" response
    if "ุนุฐุฑุงูุ ูู ุฃุฌุฏ ูุนูููุงุช" in gpt_response:
        return gpt_response
        
    # Handle both single and multiple sources
    sources_section = None
    
    if "๐ ุงููุตุฏุฑ:" in gpt_response:
        # Convert single source format to multiple source format
        gpt_response = gpt_response.replace("๐ ุงููุตุฏุฑ:", "๐ ุงููุตุงุฏุฑ:\n[1]:")
        sources_section = re.search(r'๐ ุงููุตุงุฏุฑ:(.*?)(?=\*\*|\n\n|\Z)', gpt_response, re.DOTALL)
    elif "๐ ุงููุตุงุฏุฑ:" in gpt_response:
        sources_section = re.search(r'๐ ุงููุตุงุฏุฑ:(.*?)(?=\*\*|\n\n|\Z)', gpt_response, re.DOTALL)
    
    if sources_section:
        sources_text = sources_section.group(1)
        modified_sources = []
        
        # Process each reference line
        for ref_match in re.finditer(r'\[(\d+)\]:\s*(.*?)(?=\s*-|\n|$)', sources_text):
            ref_num = ref_match.group(1)
            section_name = ref_match.group(2).strip()
            page_number = TOC_PAGE_MAP.get(section_name)
            if page_number:
                modified_sources.append(f'[{ref_num}]: {section_name} - ุตูุญุฉ {page_number}')
        
        if modified_sources:
            # Replace the sources section while preserving the rest of the response
            new_sources = '๐ ุงููุตุงุฏุฑ:\n' + '\n'.join(modified_sources)
            gpt_response = re.sub(
                r'๐ ุงููุตุงุฏุฑ:.*?(?=\*\*|\n\n|\Z)',
                new_sources,
                gpt_response,
                flags=re.DOTALL
            )
    
    return gpt_response

# Initialize document processor
DOC_PROCESSOR = DocumentProcessor()
DOC_PROCESSOR.load_document()

@app.route('/api/ask', methods=['POST', 'OPTIONS'])
def ask_question():
    if request.method == "OPTIONS":
        return _build_cors_preflight_response()
    
    data = request.json
    question = data.get('question')
    
    if not question:
        return jsonify({"error": "ูู ูุชู ุชูุฏูู ุณุคุงู"}), 400

    logger.info(f"Received question: {question}")
    
    if not DOC_PROCESSOR.sections:
        return jsonify({"error": "ูู ูุชู ุชุญููู ุงููุซููุฉ ุจุดูู ุตุญูุญ."}), 500

    # Format document sections
    context_parts = []
    for section, content in DOC_PROCESSOR.sections.items():
        context_parts.append(f"""
=== {section} ===
{content}
=== ููุงูุฉ {section} ===
""")
    
    context = "\n\n".join(context_parts)
    
    answer = ask_gpt4(question, context)
    return jsonify({"answer": answer})

@app.route('/api/sections', methods=['GET'])
def list_sections():
    """Debug endpoint to list all document sections"""
    if not DOC_PROCESSOR.sections:
        return jsonify({"error": "Document not loaded"}), 500
        
    sections = []
    for section, content in DOC_PROCESSOR.sections.items():
        sections.append({
            "title": section,
            "char_count": len(content),
            "page": TOC_PAGE_MAP.get(section, "ุบูุฑ ูุชููุฑ")
        })
    
    return jsonify({"sections": sections})

def _build_cors_preflight_response():
    response = make_response()
    response.headers.add('Access-Control-Allow-Origin', 'https://superlative-belekoy-1319b4.netlify.app')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type')
    response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')
    return response

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "healthy",
        "document_loaded": bool(DOC_PROCESSOR.sections),
        "document_path": DOCUMENT_PATH,
        "sections_count": len(DOC_PROCESSOR.sections)
    }), 200

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
