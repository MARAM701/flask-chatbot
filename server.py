from flask import Flask, request, jsonify, make_response
from flask_cors import CORS
import logging
import os
import re
import json
from openai import OpenAI

# Set up logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('server')

JSON_FILE_PATH = os.getenv('JSON_FILE_PATH', 'report_2016.json')
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

app = Flask(__name__)
CORS(app, 
    resources={
        r"/api/*": {
            "origins": ["https://superlative-belekoy-1319b4.netlify.app"],
            "methods": ["POST", "OPTIONS"],
            "allow_headers": ["Content-Type"],
            "expose_headers": ["Access-Control-Allow-Origin"],
            "supports_credentials": True
        }
    })

# Load JSON data at server startup
REPORT_DATA = []

def load_json_data():
    """Load and preprocess the JSON file at server startup"""
    global REPORT_DATA
    try:
        current_dir = os.getcwd()
        logger.info(f"Current working directory: {current_dir}")
        
        json_path = os.path.join(current_dir, JSON_FILE_PATH)
        logger.info(f"Loading JSON file from: {json_path}")
        
        with open(json_path, 'r', encoding='utf-8') as file:
            REPORT_DATA = json.load(file)
            
        logger.info(f"Successfully loaded {len(REPORT_DATA)} sections from JSON file")
        return True
    except Exception as e:
        logger.error(f"Error loading JSON file: {str(e)}", exc_info=True)
        return False

def ask_gpt4(question, context):
    """Send the document and question to OpenAI GPT-4 API."""
    client = OpenAI(api_key=OPENAI_API_KEY)
    
    system_prompt = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©.
    ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙˆØ§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¨Ø´ÙƒÙ„ ØµØ§Ø±Ù…:

    1. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø£Ø®ÙˆØ°Ø© Ù…Ù† Ù‚Ø³Ù… ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·:
    **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:** 
    [Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø§Ù„Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ] [1]

    **Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:**
    "[Ø£ÙˆÙ„ 50 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³]..."
    
    ğŸ“– Ø§Ù„Ù…ØµØ¯Ø±:
    [Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù] - [Ø§Ø³Ù… Ø§Ù„Ù‚Ø³Ù…]

    2. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø£Ø®ÙˆØ°Ø© Ù…Ù† Ø¹Ø¯Ø© Ø£Ù‚Ø³Ø§Ù…:
    **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**
    [Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø§Ù„Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹ Ø¨Ø¹Ø¯ ÙƒÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø©]

    **Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:**
    [1]: "[Ø£ÙˆÙ„ 30 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³]..."
    [2]: "[Ø£ÙˆÙ„ 30 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚ØªØ¨Ø³]..."
    
    ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:
    [1]: [Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù] - [Ø§Ø³Ù… Ø§Ù„Ù‚Ø³Ù…]
    [2]: [Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù] - [Ø§Ø³Ù… Ø§Ù„Ù‚Ø³Ù…]

    3. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ÙÙŠ Ø§Ù„Ù†ØµØŒ Ø§ÙƒØªØ¨:
    **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:** Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ø§Ù„Ù†Øµ ØªØ¬ÙŠØ¨ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„.

    4. Ø§Ù„ØªØ²Ù… Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ§Ù„ÙŠØ©:
    - Ø§Ø¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†Øµ
    - Ø§Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ù‚Ø¨Ù„ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
    - Ø£Ø¶Ù Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹ [N] Ø¨Ø¹Ø¯ ÙƒÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ù‚ØªØ¨Ø³Ø©
    - Ø§Ù‚ØªØ¨Ø³ ÙÙ‚Ø· Ø£ÙˆÙ„ 50 Ø­Ø±Ù Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ Ù…ØªØ¨ÙˆØ¹Ø© Ø¨Ø«Ù„Ø§Ø« Ù†Ù‚Ø§Ø· (...)
    - Ø±ØªØ¨ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø­Ø³Ø¨ Ø¸Ù‡ÙˆØ±Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"""

    user_message = f"""Ù‚Ù… Ø¨Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ§Ø±Ø¯Ø©.
    ØªØ£ÙƒØ¯ Ù…Ù† Ø°ÙƒØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©.

Ø§Ù„Ù†Øµ:
{context}

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {question}"""

    try:
        response = client.chat.completions.create(
            model="chatgpt-4o-latest",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            temperature=0.1,
            max_tokens=1500
        )
        
        gpt_response = response.choices[0].message.content
        return process_gpt_response(gpt_response)
            
    except Exception as e:
        logger.error(f"Error calling OpenAI API: {str(e)}")
        return "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨."

def process_gpt_response(gpt_response):
    """Format GPT response with simplified reference format"""
    # Check if it's a "no information found" response
    if "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª" in gpt_response:
        return gpt_response
        
    # Handle both single and multiple sources
    sources_section = None
    
    if "ğŸ“– Ø§Ù„Ù…ØµØ¯Ø±:" in gpt_response:
        # Convert single source format to multiple source format
        gpt_response = gpt_response.replace("ğŸ“– Ø§Ù„Ù…ØµØ¯Ø±:", "ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:\n[1]:")
        sources_section = re.search(r'ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:(.*?)(?=\*\*|\n\n|\Z)', gpt_response, re.DOTALL)
    elif "ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:" in gpt_response:
        sources_section = re.search(r'ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø±:(.*?)(?=\*\*|\n\n|\Z)', gpt_response, re.DOTALL)
    
    # We're not modifying the sources as we don't need page numbers anymore
    # The GPT response already contains the correct format for the sources
    
    return gpt_response

@app.route('/api/ask', methods=['POST', 'OPTIONS'])
def ask_question():
    if request.method == "OPTIONS":
        return _build_cors_preflight_response()
    
    data = request.json
    question = data.get('question')
    
    if not question:
        return jsonify({"error": "Ù„Ù… ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ… Ø³Ø¤Ø§Ù„"}), 400

    logger.info(f"Received question: {question}")
    
    if not REPORT_DATA:
        return jsonify({"error": "Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­."}), 500

    # Format JSON data as context
    context_parts = []
    for section in REPORT_DATA:
        file_name = section.get('file_name', '')
        section_header = section.get('section_header', '')
        content = section.get('content', '')
        
        context_parts.append(f"""
=== {section_header} ===
{content}
=== Ù†Ù‡Ø§ÙŠØ© {section_header} ===
""")
    
    context = "\n\n".join(context_parts)
    
    answer = ask_gpt4(question, context)
    return jsonify({"answer": answer})

@app.route('/api/sections', methods=['GET'])
def list_sections():
    """Endpoint to list all document sections"""
    if not REPORT_DATA:
        return jsonify({"error": "JSON data not loaded"}), 500
        
    sections = []
    for section in REPORT_DATA:
        sections.append({
            "file_name": section.get('file_name', ''),
            "title": section.get('section_header', ''),
            "char_count": len(section.get('content', '')),
        })
    
    return jsonify({"sections": sections})

def _build_cors_preflight_response():
    response = make_response()
    response.headers.add('Access-Control-Allow-Origin', 'https://superlative-belekoy-1319b4.netlify.app')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type')
    response.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')
    return response

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "healthy",
        "document_loaded": bool(REPORT_DATA),
        "json_file_path": JSON_FILE_PATH,
        "sections_count": len(REPORT_DATA)
    }), 200

# Load the JSON data when the server starts
load_json_data()

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
